Why Conv1D?
维度实际上是对信息的表示方式，这里采用CNN是为了将四个观察到的feature进行信息提取，得到真正决定机器是否正常运转的信息。并且得到一维序列前后的关系--时序关系。那么为什么不使用Conv2D甚至更高维度的卷积层呢？实际上可以通过设置stride和pool_size来实现降维：将一维数据通过reshape得到高维数据，在其中使用(1,n)的卷积核，设置合理的strides来同样做到对时间序列的信息提取这就相当于退化到一维卷积，但是会消耗更多的算力。如果多维的卷积不退化为1D的卷积操作，Con1D的权重只在一个维度上--时间维度上共享权重，但是多维卷积会在多维上共享权重，这可能会使得模型过于复杂，有过拟合的风险。

加入lstm的原因？
引入长短期神经网络，因为CNN强调对局部特征的提取，然而异常检测的问题是在一个长期的时间序列上考虑的，所以可以引入一些能够保存长期信息的模型-LSTM。

融合两个模型的技巧：
1. CNN只是针对整体的输入序列进行卷积，然而LSTM是在时间维度上进行学习，所以将CNN包装在TimeDistributed层里。
2. CNN的输出是根据上一层的输入来定的，在每个time_step都是((feature-kernel_size)/strides+1, neuron)，然而LSTM针对的是一维数据，所以需要将CNN在非时间维度上的输出使用Flatten()层展平。
reasoning
Layer的kernel size和neuron，首先随便试了一个size，但是表现不是很好，于是考虑是否有相关的时间序列的任务，在他们的网络架构和超参数的基础上根据预测结果的Accuracy不断调整。
确定两层CNN和一层LSTM的过程：
首先尝试了论文的中结构，但是发现CNN增多时表现在变差，可能是模型过于复杂了，于是尝试减少CNN和LSTM的数量，最终在2*CNN + 1*LSTM时Accuracy最高。

阈值的确定，这里并没有选择最大化precision 或者recall，而是选择平衡二者，即最大化F1-score。于是选择了能够使得F1-score最大的阈值th。


Comment on 7.1.5:
当seq从30到40后，同样的网络结构得到的预测结果准确率表现不稳定。

猜测：
模型欠拟合 1
模型不是最优 2

There are two hypotheses不稳定性

1. 增大epoch，在test set上得到表现结果，观察模型是否欠拟合。结果如下
2. 在将网络改得更复杂或者更简单后，发现模型的表现会变差，说明当前模型是预测这个问题的最优网络，所以不是模型的问题。

结论，seq_len=40并不是最优的超参设置。